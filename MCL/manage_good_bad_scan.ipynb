{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the follow one or two for updating, for orginal creating, go below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index.htmlneed_manual\n",
      "grotc.pngneed_manual\n",
      "grotf.pngneed_manual\n",
      "groti.pngneed_manual\n",
      "grotb.pngneed_manual\n",
      "groth.pngneed_manual\n",
      "grota.pngneed_manual\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv('/nfs/masi/MCL/QA/maintain_SCANlist/20201203/goodscan_list.csv')\n",
    "new_sess = []\n",
    "new_label = []\n",
    "for i, item in df.iterrows():\n",
    "    tmp_label = item['good_scan_label'] \n",
    "    tmp_vec = tmp_label.split('_') \n",
    "    try:\n",
    "        assert len(tmp_vec) == 3 and len(tmp_vec[1]) == 8\n",
    "        new_sess.append(tmp_vec[0] + '_' + tmp_vec[1])\n",
    "        new_label.append(tmp_vec[2])\n",
    "    except:\n",
    "        print (tmp_label) \n",
    "\n",
    "df = pd.read_csv('/nfs/masi/MCL/QA/maintain_SCANlist/20201114/good_scan_on_xnat_riqiang.csv')\n",
    "data = pd.DataFrame()\n",
    "data['session_list'] = df['session_list'].tolist() + new_sess \n",
    "data['scan_label_list'] = df['scan_label_list'].tolist() + new_label\n",
    "data['organ_time'] = df['organ_time'].tolist() + ['20201203'] * len(new_sess)\n",
    "data.to_csv('/nfs/masi/MCL/QA/maintain_SCANlist/20201203/good_scan_on_xnat_riqiang.csv', index = False)\n",
    "#df.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'grota.pngneed_manual', 'groth.pngneed_manual', 'grotb.pngneed_manual', 'index.htmlneed_manual', 'groti.pngneed_manual', 'grotf.pngneed_manual', 'grotc.pngneed_manual'}\n"
     ]
    }
   ],
   "source": [
    "# set usable on download_report.csv\n",
    "goodscanlist = pd.read_csv('/nfs/masi/MCL/QA/maintain_SCANlist/20201203/goodscan_list.csv')['good_scan_label'].tolist()\n",
    "\n",
    "df = pd.read_csv('/nfs/masi/MCL/xnat/xnat20201203_EDRN/download_report.csv')\n",
    "#print (df.keys())\n",
    "usable = []\n",
    "usable_list = []\n",
    "for i, item in df.iterrows():\n",
    "    if item['session_label'] +  '_' + str(item['as_label']).replace('.0', '') in goodscanlist:\n",
    "        usable.append(1)\n",
    "        usable_list.append(item['session_label'] +  '_' + str(item['as_label']).replace('.0', ''))\n",
    "    else:\n",
    "        usable.append(0)\n",
    "df['new_usable'] = usable\n",
    "df.to_csv('/nfs/masi/MCL/xnat/xnat20201203_EDRN/download_report.csv', index = False)\n",
    "print (set(goodscanlist) - set(usable_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'21938429886_20191004'}\n",
      "135\n"
     ]
    }
   ],
   "source": [
    "# tmp \n",
    "df = pd.read_csv('/nfs/masi/MCL/xnat/xnat20201203_EDRN/download_report.csv')\n",
    "all_sess = df['session_label'].tolist()\n",
    "df = df.query('new_usable == 1')\n",
    "good_sess = df['session_label'].tolist()\n",
    "print (set(all_sess) - set(good_sess))\n",
    "print (len(set(all_sess)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['35723315377', '08', '01', '2014']\n",
      "['35723315377', '08', '01', '2014']\n",
      "['35723315377', '08', '01', '2014']\n",
      "['35723315377', '08', '01', '2014']\n",
      "['35723315377', '08', '01', '2014']\n",
      "['35723315377', '08', '01', '2014']\n",
      "35 35\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "# mov problematic items\n",
    "\n",
    "df = pd.read_csv('/nfs/masi/MCL/xnat/xnat20201116_scancheck_miss/instanceN_scan.csv')\n",
    "df = df.loc[df['auto'] == 'bad']\n",
    "instN_badlist = []\n",
    "for i, item in df.iterrows():\n",
    "    tmp_vec = re.split('[-_]', item['sess'])\n",
    "    if tmp_vec[0] == tmp_vec[1]:\n",
    "        scan_name = tmp_vec[1] + '_' + tmp_vec[2]\n",
    "        try:\n",
    "            assert(len(tmp_vec[2]) == 8)\n",
    "        except:\n",
    "            print (tmp_vec)\n",
    "    else:\n",
    "        scan_name = tmp_vec[0] + '_' + tmp_vec[1]\n",
    "        try:\n",
    "            assert(len(tmp_vec[1]) == 8)\n",
    "        except:\n",
    "            print (tmp_vec)\n",
    "    scan_name = scan_name + '_' + item['scan'].split('-x-')[0]\n",
    "    instN_badlist.append(scan_name)\n",
    "print (len(instN_badlist), len(set(instN_badlist)))\n",
    "instN_dict = {}\n",
    "for i in range(len(instN_badlist)):\n",
    "    if instN_badlist[i] not in instN_dict.keys():\n",
    "        instN_dict[instN_badlist[i]]  = 0\n",
    "    else:\n",
    "        print (instN_badlist[i])\n",
    "\n",
    "def get_scan_label(path):\n",
    "    tmp_vec = re.split('[-_]', path)\n",
    "    try:\n",
    "        if tmp_vec[-1].isnumeric():\n",
    "            tmp_path = tmp_vec[-3] + '_' + tmp_vec[-2] + '_' + tmp_vec[-1]\n",
    "        else:\n",
    "            tmp_path = tmp_vec[-4] + '_' + tmp_vec[-3] + '_' + tmp_vec[-2] + '-' + tmp_vec[-1]\n",
    "    except:\n",
    "        tmp_path = ''\n",
    "    return tmp_path\n",
    "\n",
    "ori_root = '/nfs/masi/MCL/QA/SCAN_SLICEdir/xnat20201116/slicesdir'\n",
    "new_root = '/nfs/masi/MCL/QA/SCAN_SLICEdir/xnat20201116/instNbad_slicesdir'\n",
    "if not os.path.exists(new_root):\n",
    "    os.mkdir(new_root)\n",
    "\n",
    "data_list = os.listdir(ori_root)\n",
    "cnt  = 0\n",
    "for i in range(len(data_list)):\n",
    "    scan_label = get_scan_label(data_list[i].split('-x-')[0])\n",
    "    if scan_label in instN_badlist:\n",
    "        cnt += 1\n",
    "        os.system('mv ' + ori_root + '/' + data_list[i] + ' ' + new_root)\n",
    "print (cnt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# step 0: got all list (good and bad)\n",
    "\n",
    "csv_paths = ['/nfs/masi/MCL/xnat/root_instanceN_scan.csv']\n",
    "data_root = '/nfs/masi/MCL/xnat'\n",
    "\n",
    "scan_label = []\n",
    "source = []\n",
    "\n",
    "df = pd.read_csv('/nfs/masi/MCL/xnat/root_instanceN_scan.csv')\n",
    "for i, item in df.iterrows():\n",
    "    scan_label.append(item['sess'] + '_' + str(item['LABEL']).replace('.0', ''))\n",
    "    source.append('MCL_')\n",
    "    \n",
    "data_list = os.listdir(data_root)\n",
    "for folder in data_list:\n",
    "    if os.path.exists(data_root + '/' + folder + '/instanceN_scan.csv'):\n",
    "        csv_paths.append(data_root + '/' + folder + '/instanceN_scan.csv')\n",
    "        df = pd.read_csv(data_root + '/' + folder + '/instanceN_scan.csv')\n",
    "        for i, item in df.iterrows():\n",
    "            scan_label.append(item['sess'] + '_' + str(item['LABEL']).replace('.0', ''))\n",
    "            source.append(folder)\n",
    "data = pd.DataFrame()\n",
    "data['scan_label'] = scan_label\n",
    "data['source'] = source\n",
    "data.to_csv('/nfs/masi/MCL/QA/SCAN_SLICEdir/allscan_list.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1. Save all the new_max file into a single csv\n",
    "\n",
    "data_root = '/nfs/masi/MCL/xnat'\n",
    "data_list = os.listdir(data_root)\n",
    "scan_csvs = ['/nfs/masi/MCL/xnat/root_instanceN_scan.csv']\n",
    "for item in data_list:\n",
    "    if os.path.exists(data_root + '/' + item + '/instanceN_scan.csv'):\n",
    "        #print (data_root + '/' + item + '/instanceN_scan.csv')\n",
    "        scan_csvs.append(data_root + '/' + item + '/instanceN_scan.csv')\n",
    "new_max_list = []\n",
    "all_sess = []\n",
    "for csv_path in scan_csvs:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df = df.loc[(df['scan'] == 'new_max') ] # | (df['scan'] == 'file0')\n",
    "    for i, item in df.iterrows():\n",
    "        scan_label = item['sess'] + '-x-' + str(item['LABEL']).replace('.0', '')\n",
    "        new_max_list.append(scan_label)\n",
    "        all_sess.append(item['sess'])\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data['sess_label-x-SCAN_label'] = new_max_list\n",
    "data.to_csv('/nfs/masi/MCL/QA/maintain_SCANlist/20201114/new_max_folder.csv', index = False)\n",
    "\n",
    "# some good sessions do not have a new_max fold, so we miss good session in the new_max_folder. \n",
    "# sess next\n",
    "\n",
    "# problem\n",
    "# some of the LABEL are nan, may need manual correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'/nfs/masi/MCL/QA/maintain_list/20201015/uptonow_good.csv' does not exist: b'/nfs/masi/MCL/QA/maintain_list/20201015/uptonow_good.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-254-3bcb9a03c8d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#     tmp_vec1 = re.split('[_-]', sess1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/nfs/masi/MCL/QA/maintain_list/20201015/uptonow_good.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mgood_sess_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sess'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mgood_norm_sess_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnorm_sessname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msess\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgood_sess_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'/nfs/masi/MCL/QA/maintain_list/20201015/uptonow_good.csv' does not exist: b'/nfs/masi/MCL/QA/maintain_list/20201015/uptonow_good.csv'"
     ]
    }
   ],
   "source": [
    "# step 2: got the good list from mantain sess list\n",
    "def norm_sessname(sess):\n",
    "    tmp_vec = re.split('[_-]', sess.strip())\n",
    "    if len(tmp_vec) < 2:\n",
    "        print (sess)\n",
    "        return ''\n",
    "    if tmp_vec[0] != tmp_vec[1] and len(tmp_vec[1]) == 8:\n",
    "        res = tmp_vec[0] + '_' + tmp_vec[1]\n",
    "    elif tmp_vec[0] == tmp_vec[1] and len(tmp_vec[2]) == 8:\n",
    "        res = tmp_vec[1] + '_' + tmp_vec[2]\n",
    "    elif len(tmp_vec) >= 4 and len(tmp_vec[1]) == 2:\n",
    "        assert len(tmp_vec[2]) == 2 and len(tmp_vec[3]) == 4\n",
    "        res = tmp_vec[0] + '_' + tmp_vec[3] + tmp_vec[1] + tmp_vec[2]\n",
    "    else:\n",
    "        print (sess)\n",
    "        return ''\n",
    "    return res\n",
    "        \n",
    "# def issame_SessStr(sess1, sess2):\n",
    "#     tmp_vec1 = re.split('[_-]', sess1)\n",
    "    \n",
    "df = pd.read_csv('/nfs/masi/MCL/QA/maintain_list/20201015/uptonow_good.csv')\n",
    "good_sess_list = df['sess'].tolist()\n",
    "good_norm_sess_list = [norm_sessname(sess) for sess in good_sess_list]\n",
    "print (len(good_norm_sess_list))\n",
    "df = pd.read_csv('/nfs/masi/MCL/QA/maintain_SCANlist/20201114/new_max_folder.csv')\n",
    "good_from_sessgoodlist = []\n",
    "for i, item in df.iterrows():\n",
    "    norm_sess = norm_sessname(item['sess_label-x-SCAN_label'].split('-x-')[0])\n",
    "    if len(norm_sess) != 0  and norm_sess in good_norm_sess_list:\n",
    "        good_from_sessgoodlist.append(1)\n",
    "    else:\n",
    "        good_from_sessgoodlist.append(0)\n",
    "print (sum(good_from_sessgoodlist), len(good_from_sessgoodlist))\n",
    "df['good_from_sessgoodlist'] = good_from_sessgoodlist\n",
    "df.to_csv('/nfs/masi/MCL/QA/maintain_SCANlist/20201114/new_max_folder.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4197\n",
      "5650\n"
     ]
    }
   ],
   "source": [
    "# tmp\n",
    "\n",
    "df = pd.read_csv('/nfs/masi/MCL/QA/maintain_SCANlist/20201114/new_max_folder.csv')\n",
    "sess = df['sess_label-x-SCAN_label'].tolist()\n",
    "print (len(set(sess)))\n",
    "print (len(df))\n",
    "#print (sum(df['update_good_from_sessgoodlist']), sum(df['good_from_sessgoodlist']))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148 152 4\n"
     ]
    }
   ],
   "source": [
    "# step 3: got detailed good bad list from slidesdir and instanceN_scan.csv\n",
    "\n",
    "#version 1: \n",
    "\n",
    "root = '/nfs/masi/MCL/QA/SCAN_SLICEdir/xnat20201203'\n",
    "f = open(root + '/readme.txt')\n",
    "lines = f.readlines()\n",
    "lines = [line.strip().split(' ')[0] for line in lines]\n",
    "lines = [line.split('/')[-1] for line in lines]\n",
    "lines = [line for line in lines if len(line) > 0]\n",
    "data_list = os.listdir(root + '/slicesdir')\n",
    "data = pd.DataFrame()\n",
    "data['bad_scan'] = lines\n",
    "\n",
    "data.to_csv(root + '/badscan_list.csv', index = False)\n",
    "\n",
    "good_list = list(set(data_list) - set(lines))\n",
    "print (len(good_list), len(set(data_list)), len(set(lines)))\n",
    "data = pd.DataFrame()\n",
    "data['good_scan'] = good_list\n",
    "data.to_csv(root + '/goodscan_list.csv', index = False)\n",
    "\n",
    "# version 2: good list:\n",
    "\n",
    "# root = '/nfs/masi/MCL/QA/SCAN_SLICEdir/xnat20201015'\n",
    "# f = open(root + '/goodlist.txt')\n",
    "# lines = f.readlines()\n",
    "# lines = [line.strip().split(' ')[0] for line in lines]\n",
    "# lines = [line.split('/')[-1] for line in lines]\n",
    "# lines = [line for line in lines if len(line) > 0]\n",
    "# data_list = os.listdir(root + '/slicesdir')\n",
    "# data = pd.DataFrame()\n",
    "# data['good_scan'] = lines\n",
    "\n",
    "# data.to_csv(root + '/goodscan_list.csv', index = False)\n",
    "\n",
    "# good_list = list(set(data_list) - set(lines))\n",
    "# print (len(good_list), len(set(data_list)), len(set(lines)))\n",
    "# data = pd.DataFrame()\n",
    "# data['bad_scan'] = good_list\n",
    "# data.to_csv(root + '/badscan_list.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4: got scan label from scan list\n",
    "def got_scan_label(scan_name):\n",
    "    tmp_str = scan_name.split('-x-')[0].split('MCL_')[-1]\n",
    "    tmp_more_vec = re.split('[-_]', tmp_str)\n",
    "    if len(tmp_more_vec) >= 7:\n",
    "        tmp_vec = tmp_str.split('_')\n",
    "        scan_label = tmp_vec[-3] + '_' + tmp_vec[-2] + '_' + tmp_vec[-1]\n",
    "    elif len(tmp_more_vec) == 4 or len(tmp_more_vec) == 5:\n",
    "        subj_len = len(tmp_more_vec[0])\n",
    "        scan_label = tmp_str[(subj_len + 1):]\n",
    "    else:\n",
    "        scan_label = tmp_str + 'need_manual' # leave from maunal correct\n",
    "    return scan_label\n",
    "    \n",
    "#got_scan_label('_nfs_masi_MCL_xnat_MCL_9291060132_9291060132-20060223_9291060132_9291060132-20060223_3-x-Recon2:W-x-Recon2_W_new_NIFTI_item0.png')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/nfs/masi/MCL/QA/SCAN_SLICEdir/xnat20201203'\n",
    "df = pd.read_csv(root + '/goodscan_list.csv')\n",
    "good_list = df['good_scan'].tolist()\n",
    "good_scan_label = [got_scan_label(scan_name) for scan_name in good_list]\n",
    "df['good_scan_label'] = good_scan_label\n",
    "df.to_csv(root + '/goodscan_list.csv', index = False)\n",
    "\n",
    "df = pd.read_csv(root + '/badscan_list.csv')\n",
    "good_list = df['bad_scan'].tolist()\n",
    "good_scan_label = [got_scan_label(scan_name) for scan_name in good_list]\n",
    "df['bad_scan_label'] = good_scan_label\n",
    "df.to_csv(root + '/badscan_list.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allscan_list.csv\n",
      "allscan_list.csv error\n",
      "xnat20200815_decamp3\n",
      "all_goodscan_list.csv\n",
      "all_goodscan_list.csv error\n",
      "xnat20201031\n",
      "xnat20201118_onlymanual\n",
      "xnat20200131\n",
      "xnat20200131 error\n",
      "xnat20201112\n",
      "xnat20201015\n",
      "xnat20200815_decamp2\n",
      "xnat20200120\n",
      "xnat20200127\n",
      "xnat20200311\n",
      "xnat20200311 error\n",
      "xnat20200115\n",
      "xnat20200902\n",
      "xnat20200504\n",
      "xnat20200306\n",
      "xnat20200201\n",
      "xnat20200201 error\n",
      "xnat20200306_150toall\n",
      "xnat20200130\n",
      "xnat20200130 error\n",
      "MCL_\n",
      "xnat20200815_decamp1\n",
      "xnat20200111\n",
      "xnat20200111 error\n",
      ".~lock.allscan_list.csv#\n",
      ".~lock.allscan_list.csv# error\n",
      "missedincsv_before0330\n",
      "xnat20200901\n",
      "xnat20201003_moffti2\n",
      "shayan20200326\n",
      "xnat20201116\n",
      "4011 3853\n"
     ]
    }
   ],
   "source": [
    "# step 5: get together goodscan_list.csv\n",
    "\n",
    "# 5.1 \n",
    "# data_root = '/nfs/masi/MCL/QA/SCAN_SLICEdir/MCL_'\n",
    "# data_list = os.listdir(data_root)\n",
    "# good_list = []\n",
    "# for item in data_list:\n",
    "#     if not os.path.exists(data_root + '/' + item + '/goodscan_list.csv'):\n",
    "#         print (item)\n",
    "#     else:\n",
    "#         df = pd.read_csv(data_root + '/' + item + '/goodscan_list.csv')\n",
    "#         df = df.loc[df['good_scan_label'] == df['good_scan_label']]\n",
    "#         good_list += df['good_scan_label'].tolist()\n",
    "# print (len(good_list), len(set(good_list)))\n",
    "# data = pd.DataFrame()\n",
    "# data['good_scan_label'] = list(set(good_list))\n",
    "# data.to_csv(data_root + '/goodscan_list.csv', index = False)\n",
    "\n",
    "# 5.2\n",
    "\n",
    "data_root = '/nfs/masi/MCL/QA/SCAN_SLICEdir'\n",
    "\n",
    "data_list = os.listdir(data_root)\n",
    "good_list = []\n",
    "source_list = []\n",
    "for item in data_list:\n",
    "    print (item)\n",
    "    if not os.path.exists(data_root + '/' + item + '/goodscan_list.csv'):\n",
    "        print (item + ' error')\n",
    "    else:\n",
    "        df = pd.read_csv(data_root + '/' + item + '/goodscan_list.csv')\n",
    "        df = df.loc[df['good_scan_label'] == df['good_scan_label']]\n",
    "        good_list += df['good_scan_label'].tolist()\n",
    "        source_list += [item] * len(df)\n",
    "print (len(good_list), len(set(good_list)))\n",
    "data = pd.DataFrame()\n",
    "data['good_scan_label'] = good_list\n",
    "data['source'] = source_list\n",
    "data.to_csv(data_root + '/all_goodscan_list.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/nfs/masi/MCL/QA/SCAN_SLICEdir'\n",
    "df = pd.read_csv(data_root + '/all_goodscan_list.csv')\n",
    "# df = df.loc[df['source'] != 'xnat20201031']\n",
    "# df = df.loc[df['source'] != 'xnat20201112']\n",
    "mclid_date = []\n",
    "mcl_scan = []\n",
    "\n",
    "for i, item in df.iterrows():\n",
    "    tmp_vec = re.split('[-_]', item['good_scan_label'])\n",
    "    if len(tmp_vec) < 2:\n",
    "        continue\n",
    "    mcl_scan.append(item['good_scan_label'])\n",
    "    if tmp_vec[0] == tmp_vec[1]:\n",
    "        mclid_date.append(tmp_vec[1] + '_' + tmp_vec[2])\n",
    "    else:\n",
    "        mclid_date.append(tmp_vec[0] + '_' + tmp_vec[1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13899683756_04_27\n",
      "23797390280_06\n",
      "18880161965_04_03\n",
      "23797390280_04\n",
      "18880161965_04\n",
      "20817757605_07_16\n",
      "18880161965_11_14\n",
      "42157034411_05\n",
      "18880161965_03_13\n",
      "18880161965_05\n",
      "7107891308_04_12\n",
      "18880161965_08\n",
      "13198007362_05_02\n",
      "35016263731_04_03\n",
      "40437992060_08\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/nfs/masi/MCL/QA/maintain_list/20201015/uptonow_good_manual.csv')\n",
    "\n",
    "mclid_date_fromsess = []\n",
    "\n",
    "for i, item in df.iterrows():\n",
    "    tmp_vec = re.split('[-_]', item['sess'])\n",
    "    if len(tmp_vec) < 2:\n",
    "        continue\n",
    "    try:\n",
    "        if tmp_vec[0] == tmp_vec[1]:\n",
    "            #assert len(tmp_vec[2]) == 8\n",
    "            mclid_date_fromsess.append(tmp_vec[1] + '_' + tmp_vec[2])\n",
    "        else:\n",
    "            if len(tmp_vec[1]) == 8:\n",
    "                mclid_date_fromsess.append(tmp_vec[0] + '_' + tmp_vec[1])\n",
    "            elif len(tmp_vec[1]) == 2 and len(tmp_vec[2]) == 2 and len(tmp_vec[3]) == 4:\n",
    "                mclid_date_fromsess.append(tmp_vec[0] + '_' + tmp_vec[3] + tmp_vec[1] + tmp_vec[2] )\n",
    "    except:\n",
    "        print (item['sess'])\n",
    "                \n",
    "df = pd.read_csv('/nfs/masi/MCL/QA/maintain_SCANlist/20201114/new_max_folder.csv')\n",
    "df = df.query('good_from_sessgoodlist == 1')\n",
    "mclid_date_frommax = []\n",
    "mcl_scan_frommax = []\n",
    "for i, item in df.iterrows():\n",
    "    tmp_vec = re.split('[-_]', item['sess_label-x-SCAN_label'])\n",
    "    mcl_scan_frommax.append(item['sess_label-x-SCAN_label'])\n",
    "    if len(tmp_vec) < 2:\n",
    "        continue\n",
    "    try:\n",
    "        if tmp_vec[0] == tmp_vec[1]:\n",
    "            assert len(tmp_vec[2]) == 8\n",
    "            mclid_date_frommax.append(tmp_vec[1] + '_' + tmp_vec[2])\n",
    "        else:\n",
    "            assert len(tmp_vec[1]) == 8\n",
    "            mclid_date_frommax.append(tmp_vec[0] + '_' + tmp_vec[1])\n",
    "    except:\n",
    "        print (item['sess'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7933"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tmp \n",
    "def norm_sessname(sess):\n",
    "#     if len(sess) < 3:\n",
    "#         return ''\n",
    "    tmp_vec = re.split('[_-]', sess.strip())\n",
    "    if len(tmp_vec) < 2:\n",
    "        #print (sess)\n",
    "        return ''\n",
    "    if tmp_vec[0] != tmp_vec[1] and len(tmp_vec[1]) == 8:\n",
    "        res = tmp_vec[0] + '_' + tmp_vec[1]\n",
    "    elif tmp_vec[0] == tmp_vec[1] and len(tmp_vec[2]) == 8:\n",
    "        res = tmp_vec[1] + '_' + tmp_vec[2]\n",
    "    elif len(tmp_vec) >= 4 and len(tmp_vec[1]) == 2:\n",
    "        try:\n",
    "            assert len(tmp_vec[2]) == 2 and len(tmp_vec[3]) == 4\n",
    "            res = tmp_vec[0] + '_' + tmp_vec[3] + tmp_vec[1] + tmp_vec[2]\n",
    "        except:\n",
    "            print (tmp_vec)\n",
    "            return ''\n",
    "    else:\n",
    "        #print (sess)\n",
    "        return ''\n",
    "    return res\n",
    "mclid_date_fromsess = [norm_sessname(sess) for sess in mclid_date_fromsess]\n",
    "mclid_date_frommax = [norm_sessname(sess) for sess in mclid_date_frommax]\n",
    "mclid_date = [norm_sessname(sess) for sess in mclid_date]\n",
    "\n",
    "\n",
    "len( set(mclid_date_frommax) | set(mclid_date))\n",
    "#print (len(mclid_date), len(set(mclid_date_frommax) ))\n",
    "len(set(mcl_scan) | set(mcl_scan_frommax))\n",
    "data = pd.DataFrame()\n",
    "l = list(set(mcl_scan) | set(mcl_scan_frommax))\n",
    "data['good_scan'] = l \n",
    "data.to_csv('/nfs/masi/MCL/QA/maintain_SCANlist/20201114/good_scan.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for manual remove nan\n",
    "df = pd.read_csv('/nfs/masi/MCL/QA/maintain_SCANlist/20201114/good_scan.csv')\n",
    "for i, item in df.iterrows():\n",
    "    scan= item['good_scan'].replace('-x-', '_')\n",
    "    tmp = scan.split('_')[-1]\n",
    "    if tmp == 'nan':\n",
    "        print (item['good_scan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20817757605', '07', '16', '402']\n",
      "['20817757605', '07', '16', '3']\n",
      "['20817757605', '07', '16', '2']\n"
     ]
    }
   ],
   "source": [
    "# norm good scan\n",
    "df = pd.read_csv('/nfs/masi/MCL/QA/maintain_SCANlist/20201114/good_scan.csv')\n",
    "good_scan_list = []\n",
    "session_list = []\n",
    "scan_label_list = []\n",
    "for i, item in df.iterrows():\n",
    "    scan= item['good_scan_manual_remove_nan'].replace('-x-', '_')\n",
    "    scan_label = re.split('_', scan.strip())[-1]\n",
    "    sess= norm_sessname(scan)\n",
    "    good_scan_list.append(sess + '-x-' + scan_label)\n",
    "    session_list.append(sess)\n",
    "    scan_label_list.append(scan_label)\n",
    "df['session_list'] = session_list\n",
    "df['scan_label_list'] = scan_label_list\n",
    "df.to_csv('/nfs/masi/MCL/QA/maintain_SCANlist/20201114/good_scan.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2180    37660576714_2_37660576714_2_20171003_3\n",
      "5289                       new_NIFTI_item0.png\n",
      "6191                           104051_000000_2\n",
      "Name: good_scan_manual_remove_nan, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/nfs/masi/MCL/QA/maintain_SCANlist/20201114/good_scan.csv')\n",
    "df_nll = df.query('session_list != session_list')\n",
    "print (df_nll['good_scan_manual_remove_nan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm all scan\n",
    "df = pd.read_csv('/nfs/masi/MCL/xnat/MCL_all.csv')\n",
    "all_scan_list = []\n",
    "step1_usable = []\n",
    "for i, item in df.iterrows():\n",
    "    scan_label= str(item['as_label']).replace('.0', '')\n",
    "    #scan_label = re.split('_', scan.strip())[-1]\n",
    "    sess= norm_sessname(item['session_label'])\n",
    "    if sess + '-x-' + scan_label in good_scan_list:\n",
    "        step1_usable.append(1)\n",
    "    else:\n",
    "        step1_usable.append(0)\n",
    "    all_scan_list.append(sess + '-x-' + scan_label)\n",
    "df['step1_usable'] = step1_usable\n",
    "df.to_csv('/nfs/masi/MCL/xnat/MCL_all.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'-x-201',\n",
       " '-x-202',\n",
       " '-x-203',\n",
       " '-x-301',\n",
       " '-x-item0.png',\n",
       " '10933105084_19990102-x-1',\n",
       " '10933105084_20000102-x-1',\n",
       " '10933105084_20010102-x-1',\n",
       " '1265719794_19990102-x-1',\n",
       " '1265719794_20000102-x-1',\n",
       " '1265719794_20010102-x-3',\n",
       " '12764488079_19990102-x-0',\n",
       " '13198007362_20180502-x-2',\n",
       " '13198007362_20180502-x-3',\n",
       " '13198007362_20180502-x-402',\n",
       " '13899683756_20180427-x-3',\n",
       " '13899683756_20180427-x-4',\n",
       " '13899683756_20180427-x-502',\n",
       " '14127434895_19990102-x-1',\n",
       " '14127434895_20000102-x-1',\n",
       " '14127434895_20010102-x-1',\n",
       " '14144056110_19990102-x-0',\n",
       " '14333883840_19990102-x-1',\n",
       " '14333883840_20000102-x-1',\n",
       " '14333883840_20010102-x-1',\n",
       " '14559507651_19990102-x-1',\n",
       " '14559507651_20000102-x-1',\n",
       " '14559507651_20010102-x-1',\n",
       " '1469614994_19990102-x-1',\n",
       " '1469614994_20000102-x-1',\n",
       " '1469614994_20010102-x-1',\n",
       " '15817553635_20120626-x-2',\n",
       " '16058094014_19990102-x-1',\n",
       " '16058094014_20000102-x-1',\n",
       " '16058094014_20010102-x-1',\n",
       " '17661063994_19990102-x-0',\n",
       " '18665376162_19990102-x-1',\n",
       " '18665376162_20000102-x-1',\n",
       " '18665376162_20010102-x-1',\n",
       " '18880161965_20110808-x-2',\n",
       " '18880161965_20110808-x-2-CT1',\n",
       " '18880161965_20110808-x-3',\n",
       " '18880161965_20110808-x-3-CT1',\n",
       " '18880161965_20110808-x-4',\n",
       " '18880161965_20110808-x-5',\n",
       " '18880161965_20110808-x-6',\n",
       " '18880161965_20121114-x-2',\n",
       " '18880161965_20121114-x-5',\n",
       " '18880161965_20140313-x-10',\n",
       " '18880161965_20140313-x-7',\n",
       " '18880161965_20150403-x-2',\n",
       " '18880161965_20150403-x-5',\n",
       " '18880161965_20160409-x-2',\n",
       " '18880161965_20160409-x-2-CT1',\n",
       " '18880161965_20160409-x-3',\n",
       " '18880161965_20160409-x-3-CT1',\n",
       " '18880161965_20180504-x-2',\n",
       " '18880161965_20180504-x-3',\n",
       " '19876548496_20180320-x-3',\n",
       " '20825853836_19990102-x-1',\n",
       " '20825853836_20000102-x-1',\n",
       " '20825853836_20010102-x-1',\n",
       " '20984720077_19990102-x-0',\n",
       " '21723979465_19990102-x-0',\n",
       " '23797390280_20180430-x-4',\n",
       " '23797390280_20180430-x-6',\n",
       " '23797390280_20180625-x-4',\n",
       " '24044190829_19990102-x-1',\n",
       " '24044190829_20000102-x-1',\n",
       " '24044190829_20010102-x-1',\n",
       " '24925180097_19990102-x-0',\n",
       " '25183231300_19990102-x-1',\n",
       " '25183231300_20000102-x-1',\n",
       " '25183231300_20010102-x-1',\n",
       " '29965423921_19990102-x-1',\n",
       " '29965423921_20000102-x-1',\n",
       " '29965423921_20010102-x-1',\n",
       " '31626358256_19990102-x-1',\n",
       " '31626358256_20000102-x-1',\n",
       " '31626358256_20010102-x-1',\n",
       " '33562781993_19990102-x-0',\n",
       " '33676554821_19990102-x-0',\n",
       " '34057980460_19990102-x-0',\n",
       " '34057980460_20000102-x-0',\n",
       " '34820955300_19990102-x-1',\n",
       " '34820955300_20000102-x-1',\n",
       " '34820955300_20010102-x-1',\n",
       " '35016263731_20180403-x-2',\n",
       " '35016263731_20180403-x-4',\n",
       " '35681547355_19990102-x-1',\n",
       " '35681547355_20000102-x-1',\n",
       " '35681547355_20010102-x-1',\n",
       " '39255208196_19990102-x-1',\n",
       " '39255208196_20000102-x-1',\n",
       " '39255208196_20010102-x-1',\n",
       " '40437992060_20180828-x-2',\n",
       " '40437992060_20180828-x-3',\n",
       " '40496530032_19990102-x-1',\n",
       " '40496530032_20000102-x-1',\n",
       " '40496530032_20010102-x-1',\n",
       " '40795940486_19990102-x-0',\n",
       " '42157034411_20180529-x-2',\n",
       " '4220178696_19990102-x-0',\n",
       " '508416523_19990102-x-1',\n",
       " '508416523_20000102-x-1',\n",
       " '508416523_20010102-x-1',\n",
       " '6528284862_19990102-x-0',\n",
       " '7107891308_20180412-x-2',\n",
       " '7107891308_20180412-x-3',\n",
       " '7107891308_20180412-x-5'}"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/nfs/masi/MCL/xnat/MCL_all.csv')\n",
    "cnt = 0\n",
    "session_list = []\n",
    "for i, item in df.iterrows():\n",
    "    norm_sess = norm_sessname(item['session_label'])\n",
    "    if norm_sess in missed_goodsess:\n",
    "        cnt += 1\n",
    "        session_list.append(item['session_label'])\n",
    "print (cnt)\n",
    "print (len(set(session_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'17064845823_20121026',\n",
       " '17064845823_20160209',\n",
       " '17064845823_20161028',\n",
       " '17064845823_20171024',\n",
       " '17064845823_20181012',\n",
       " '17064845823_20191018'}"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/nfs/masi/MCL/xnat/MCL_all.csv')\n",
    "sess_all = df['session_label'].tolist()\n",
    "missed_goodsess = [norm_sessname(sess) for sess in missed_goodsess]\n",
    "sess_all = [norm_sessname(sess) for sess in sess_all]\n",
    "set(missed_goodsess) - set(sess_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python37]",
   "language": "python",
   "name": "conda-env-python37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
