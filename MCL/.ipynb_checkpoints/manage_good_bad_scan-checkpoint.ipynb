{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mov problematic items\n",
    "\n",
    "\n",
    "df = pd.read_csv('/nfs/masi/MCL/xnat/xnat20201112/instanceN_scan.csv')\n",
    "df = df.loc[df['auto'] == 'bad']\n",
    "instN_badlist = []\n",
    "for i, item in df.iterrows():\n",
    "    tmp_vec = re.split('[-_]', item['sess'])\n",
    "    if tmp_vec[0] == tmp_vec[1]:\n",
    "        scan_name = tmp_vec[1] + '_' + tmp_vec[2]\n",
    "        try:\n",
    "            assert(len(tmp_vec[2]) == 8)\n",
    "        except:\n",
    "            print (tmp_vec)\n",
    "    else:\n",
    "        scan_name = tmp_vec[0] + '_' + tmp_vec[1]\n",
    "        try:\n",
    "            assert(len(tmp_vec[1]) == 8)\n",
    "        except:\n",
    "            print (tmp_vec)\n",
    "    scan_name = scan_name + '_' + item['scan'].split('-x-')[0]\n",
    "    instN_badlist.append(scan_name)\n",
    "print (len(instN_badlist), len(set(instN_badlist)))\n",
    "instN_dict = {}\n",
    "for i in range(len(instN_badlist)):\n",
    "    if instN_badlist[i] not in instN_dict.keys():\n",
    "        instN_dict[instN_badlist[i]]  = 0\n",
    "    else:\n",
    "        print (instN_badlist[i])\n",
    "\n",
    "def get_scan_label(path):\n",
    "    tmp_vec = re.split('[-_]', path)\n",
    "    try:\n",
    "        if tmp_vec[-1].isnumeric():\n",
    "            tmp_path = tmp_vec[-3] + '_' + tmp_vec[-2] + '_' + tmp_vec[-1]\n",
    "        else:\n",
    "            tmp_path = tmp_vec[-4] + '_' + tmp_vec[-3] + '_' + tmp_vec[-2] + '-' + tmp_vec[-1]\n",
    "    except:\n",
    "        tmp_path = ''\n",
    "    return tmp_path\n",
    "\n",
    "ori_root = '/nfs/masi/MCL/QA/SCAN_SLICEdir/xnat20201116/slicesdir'\n",
    "new_root = '/nfs/masi/MCL/QA/SCAN_SLICEdir/xnat20201116/instNbad_slicesdir'\n",
    "if not os.path.exists(new_root):\n",
    "    os.mkdir(new_root)\n",
    "\n",
    "data_list = os.listdir(ori_root)\n",
    "cnt  = 0\n",
    "for i in range(len(data_list)):\n",
    "    scan_label = get_scan_label(data_list[i].split('-x-')[0])\n",
    "    if scan_label in instN_badlist:\n",
    "        cnt += 1\n",
    "        os.system('mv ' + ori_root + '/' + data_list[i] + ' ' + new_root)\n",
    "print (cnt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 0: got all list (good and bad)\n",
    "csv_paths = ['/nfs/masi/MCL/xnat/root_instanceN_scan.csv']\n",
    "data_root = '/nfs/masi/MCL/xnat'\n",
    "\n",
    "scan_label = []\n",
    "source = []\n",
    "\n",
    "df = pd.read_csv('/nfs/masi/MCL/xnat/root_instanceN_scan.csv')\n",
    "for i, item in df.iterrows():\n",
    "    scan_label.append(item['sess'] + '_' + str(item['LABEL']).replace('.0', ''))\n",
    "    source.append('MCL_')\n",
    "    \n",
    "    \n",
    "data_list = os.listdir(data_root)\n",
    "for folder in data_list:\n",
    "    if os.path.exists(data_root + '/' + folder + '/instanceN_scan.csv'):\n",
    "        csv_paths.append(data_root + '/' + folder + '/instanceN_scan.csv')\n",
    "        df = pd.read_csv(data_root + '/' + folder + '/instanceN_scan.csv')\n",
    "        for i, item in df.iterrows():\n",
    "            scan_label.append(item['sess'] + '_' + str(item['LABEL']).replace('.0', ''))\n",
    "            source.append(folder)\n",
    "data = pd.DataFrame()\n",
    "data['scan_label'] = scan_label\n",
    "data['source'] = source\n",
    "data.to_csv('/nfs/masi/MCL/QA/SCAN_SLICEdir/allscan_list.csv', index = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1. Save all the new_max file into a single csv\n",
    "\n",
    "data_root = '/nfs/masi/MCL/xnat'\n",
    "data_list = os.listdir(data_root)\n",
    "scan_csvs = ['/nfs/masi/MCL/xnat/root_instanceN_scan.csv']\n",
    "for item in data_list:\n",
    "    if os.path.exists(data_root + '/' + item + '/instanceN_scan.csv'):\n",
    "        #print (data_root + '/' + item + '/instanceN_scan.csv')\n",
    "        scan_csvs.append(data_root + '/' + item + '/instanceN_scan.csv')\n",
    "new_max_list = []\n",
    "all_sess = []\n",
    "for csv_path in scan_csvs:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df = df.loc[(df['scan'] == 'new_max') ] # | (df['scan'] == 'file0')\n",
    "    for i, item in df.iterrows():\n",
    "        scan_label = item['sess'] + '-x-' + str(item['LABEL']).replace('.0', '')\n",
    "        new_max_list.append(scan_label)\n",
    "        all_sess.append(item['sess'])\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data['sess_label-x-SCAN_label'] = new_max_list\n",
    "data.to_csv('/nfs/masi/MCL/QA/maintain_SCANlist/20201114/new_max_folder.csv', index = False)\n",
    "\n",
    "# some good sessions do not have a new_max fold, so we miss good session in the new_max_folder. \n",
    "# sess next\n",
    "\n",
    "# problem\n",
    "# some of the LABEL are nan, may need manual correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13899683756_04_27\n",
      "23797390280_06\n",
      "18880161965_04_03\n",
      "23797390280_04\n",
      "5594368416_2_20190730_081000_812000\n",
      "30041657825__130053_000000\n",
      "31041894607__171930_606000\n",
      "18880161965_04\n",
      "20817757605_07_16\n",
      "18880161965_11_14\n",
      "3706595794_2_20181114\n",
      "42157034411_05\n",
      "18880161965_03_13\n",
      "5847948632_2_20190927_104258_653000\n",
      "33400829042__101902\n",
      "18880161965_05\n",
      "5594368416_1_20190128_094102\n",
      "7107891308_04_12\n",
      "19669946331__093734_859000\n",
      "18880161965_08\n",
      "13198007362_05_02\n",
      "37660576714_2_20171003\n",
      "5847948632_1_20190718_171829_437000\n",
      "35016263731_04_03\n",
      "40437992060_08\n",
      "5044\n",
      "37660576714_2_20171003\n",
      "3706595794_2_20181114\n",
      "20817757605_07_16\n",
      "5847948632_2_20190927_104258_653000\n",
      "39479816584__152913_125000\n",
      "5439 5650\n"
     ]
    }
   ],
   "source": [
    "# step 2: got the good list from mantain sess list\n",
    "def norm_sessname(sess):\n",
    "    tmp_vec = re.split('[_-]', sess.strip())\n",
    "    if len(tmp_vec) < 2:\n",
    "        print (sess)\n",
    "        return ''\n",
    "    if tmp_vec[0] != tmp_vec[1] and len(tmp_vec[1]) == 8:\n",
    "        res = tmp_vec[0] + '_' + tmp_vec[1]\n",
    "    elif tmp_vec[0] == tmp_vec[1] and len(tmp_vec[2]) == 8:\n",
    "        res = tmp_vec[1] + '_' + tmp_vec[2]\n",
    "    elif len(tmp_vec) >= 4 and len(tmp_vec[1]) == 2:\n",
    "        assert len(tmp_vec[2]) == 2 and len(tmp_vec[3]) == 4\n",
    "        res = tmp_vec[0] + '_' + tmp_vec[3] + tmp_vec[1] + tmp_vec[2]\n",
    "    else:\n",
    "        print (sess)\n",
    "        return ''\n",
    "    return res\n",
    "        \n",
    "# def issame_SessStr(sess1, sess2):\n",
    "#     tmp_vec1 = re.split('[_-]', sess1)\n",
    "    \n",
    "df = pd.read_csv('/nfs/masi/MCL/QA/maintain_list/20201015/uptonow_good.csv')\n",
    "good_sess_list = df['sess'].tolist()\n",
    "good_norm_sess_list = [norm_sessname(sess) for sess in good_sess_list]\n",
    "print (len(good_norm_sess_list))\n",
    "df = pd.read_csv('/nfs/masi/MCL/QA/maintain_SCANlist/20201114/new_max_folder.csv')\n",
    "good_from_sessgoodlist = []\n",
    "for i, item in df.iterrows():\n",
    "    norm_sess = norm_sessname(item['sess_label-x-SCAN_label'].split('-x-')[0])\n",
    "    if len(norm_sess) != 0  and norm_sess in good_norm_sess_list:\n",
    "        good_from_sessgoodlist.append(1)\n",
    "    else:\n",
    "        good_from_sessgoodlist.append(0)\n",
    "print (sum(good_from_sessgoodlist), len(good_from_sessgoodlist))\n",
    "df['good_from_sessgoodlist'] = good_from_sessgoodlist\n",
    "df.to_csv('/nfs/masi/MCL/QA/maintain_SCANlist/20201114/new_max_folder.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4197\n",
      "5650\n"
     ]
    }
   ],
   "source": [
    "# tmp\n",
    "\n",
    "df = pd.read_csv('/nfs/masi/MCL/QA/maintain_SCANlist/20201114/new_max_folder.csv')\n",
    "sess = df['sess_label-x-SCAN_label'].tolist()\n",
    "print (len(set(sess)))\n",
    "print (len(df))\n",
    "#print (sum(df['update_good_from_sessgoodlist']), sum(df['good_from_sessgoodlist']))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 13 1\n"
     ]
    }
   ],
   "source": [
    "# step 3: got detailed good bad list from slidesdir and instanceN_scan.csv\n",
    "\n",
    "#version 1: \n",
    "\n",
    "root = '/nfs/masi/MCL/QA/SCAN_SLICEdir/xnat20201112'\n",
    "f = open(root + '/readme.txt')\n",
    "lines = f.readlines()\n",
    "lines = [line.strip().split(' ')[0] for line in lines]\n",
    "lines = [line.split('/')[-1] for line in lines]\n",
    "lines = [line for line in lines if len(line) > 0]\n",
    "data_list = os.listdir(root + '/slicesdir')\n",
    "data = pd.DataFrame()\n",
    "data['bad_scan'] = lines\n",
    "\n",
    "data.to_csv(root + '/badscan_list.csv', index = False)\n",
    "\n",
    "good_list = list(set(data_list) - set(lines))\n",
    "print (len(good_list), len(set(data_list)), len(set(lines)))\n",
    "data = pd.DataFrame()\n",
    "data['good_scan'] = good_list\n",
    "data.to_csv(root + '/goodscan_list.csv', index = False)\n",
    "\n",
    "# version 2: good list:\n",
    "\n",
    "# root = '/nfs/masi/MCL/QA/SCAN_SLICEdir/xnat20201015'\n",
    "# f = open(root + '/goodlist.txt')\n",
    "# lines = f.readlines()\n",
    "# lines = [line.strip().split(' ')[0] for line in lines]\n",
    "# lines = [line.split('/')[-1] for line in lines]\n",
    "# lines = [line for line in lines if len(line) > 0]\n",
    "# data_list = os.listdir(root + '/slicesdir')\n",
    "# data = pd.DataFrame()\n",
    "# data['good_scan'] = lines\n",
    "\n",
    "# data.to_csv(root + '/goodscan_list.csv', index = False)\n",
    "\n",
    "# good_list = list(set(data_list) - set(lines))\n",
    "# print (len(good_list), len(set(data_list)), len(set(lines)))\n",
    "# data = pd.DataFrame()\n",
    "# data['bad_scan'] = good_list\n",
    "# data.to_csv(root + '/badscan_list.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9291060132_9291060132-20060223_3'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 4: got scan label from scan list\n",
    "def got_scan_label(scan_name):\n",
    "    tmp_str = scan_name.split('-x-')[0].split('MCL_')[-1]\n",
    "    tmp_more_vec = re.split('[-_]', tmp_str)\n",
    "    if len(tmp_more_vec) >= 7:\n",
    "        tmp_vec = tmp_str.split('_')\n",
    "        scan_label = tmp_vec[-3] + '_' + tmp_vec[-2] + '_' + tmp_vec[-1]\n",
    "    elif len(tmp_more_vec) == 4 or len(tmp_more_vec) == 5:\n",
    "        subj_len = len(tmp_more_vec[0])\n",
    "        scan_label = tmp_str[(subj_len + 1):]\n",
    "    else:\n",
    "        scan_label = tmp_str + 'need_manual' # leave from maunal correct\n",
    "    return scan_label\n",
    "        \n",
    "#got_scan_label('_nfs_masi_MCL_xnat_MCL_9291060132_9291060132-20060223_9291060132_9291060132-20060223_3-x-Recon2:W-x-Recon2_W_new_NIFTI_item0.png')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/nfs/masi/MCL/QA/SCAN_SLICEdir/xnat20201112'\n",
    "df = pd.read_csv(root + '/goodscan_list.csv')\n",
    "good_list = df['good_scan'].tolist()\n",
    "good_scan_label = [got_scan_label(scan_name) for scan_name in good_list]\n",
    "df['good_scan_label'] = good_scan_label\n",
    "df.to_csv(root + '/goodscan_list.csv', index = False)\n",
    "\n",
    "df = pd.read_csv(root + '/badscan_list.csv')\n",
    "good_list = df['bad_scan'].tolist()\n",
    "good_scan_label = [got_scan_label(scan_name) for scan_name in good_list]\n",
    "df['bad_scan_label'] = good_scan_label\n",
    "df.to_csv(root + '/badscan_list.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".~lock.all_goodscan_list.csv#\n",
      ".~lock.all_goodscan_list.csv# error\n",
      "xnat20200815_decamp3\n",
      "all_goodscan_list.csv\n",
      "all_goodscan_list.csv error\n",
      "xnat20201031\n",
      "xnat20200131\n",
      "xnat20200131 error\n",
      "xnat20201112\n",
      "xnat20201015\n",
      "xnat20200815_decamp2\n",
      "xnat20200120\n",
      "xnat20200127\n",
      "xnat20200311\n",
      "xnat20200311 error\n",
      "xnat20200115\n",
      "xnat20200902\n",
      "xnat20200504\n",
      "xnat20200306\n",
      "xnat20200201\n",
      "xnat20200201 error\n",
      "xnat20200306_150toall\n",
      "xnat20200130\n",
      "xnat20200130 error\n",
      "MCL_\n",
      "xnat20200815_decamp1\n",
      "xnat20200111\n",
      "xnat20200111 error\n",
      "missedincsv_before0330\n",
      "xnat20200901\n",
      "xnat20201003_moffti2\n",
      "shayan20200326\n",
      "3937 3789\n"
     ]
    }
   ],
   "source": [
    "# step 5: get together goodscan_list.csv\n",
    "\n",
    "# 5.1 \n",
    "# data_root = '/nfs/masi/MCL/QA/SCAN_SLICEdir/MCL_'\n",
    "# data_list = os.listdir(data_root)\n",
    "# good_list = []\n",
    "# for item in data_list:\n",
    "#     if not os.path.exists(data_root + '/' + item + '/goodscan_list.csv'):\n",
    "#         print (item)\n",
    "#     else:\n",
    "#         df = pd.read_csv(data_root + '/' + item + '/goodscan_list.csv')\n",
    "#         df = df.loc[df['good_scan_label'] == df['good_scan_label']]\n",
    "#         good_list += df['good_scan_label'].tolist()\n",
    "# print (len(good_list), len(set(good_list)))\n",
    "# data = pd.DataFrame()\n",
    "# data['good_scan_label'] = list(set(good_list))\n",
    "# data.to_csv(data_root + '/goodscan_list.csv', index = False)\n",
    "\n",
    "# 5.2\n",
    "\n",
    "data_root = '/nfs/masi/MCL/QA/SCAN_SLICEdir'\n",
    "\n",
    "data_list = os.listdir(data_root)\n",
    "good_list = []\n",
    "source_list = []\n",
    "for item in data_list:\n",
    "    print (item)\n",
    "    if not os.path.exists(data_root + '/' + item + '/goodscan_list.csv'):\n",
    "        print (item + ' error')\n",
    "    else:\n",
    "        df = pd.read_csv(data_root + '/' + item + '/goodscan_list.csv')\n",
    "        df = df.loc[df['good_scan_label'] == df['good_scan_label']]\n",
    "        good_list += df['good_scan_label'].tolist()\n",
    "        source_list += [item] * len(df)\n",
    "print (len(good_list), len(set(good_list)))\n",
    "data = pd.DataFrame()\n",
    "data['good_scan_label'] = good_list\n",
    "data['source'] = source_list\n",
    "data.to_csv(data_root + '/all_goodscan_list.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/nfs/masi/MCL/QA/SCAN_SLICEdir'\n",
    "df = pd.read_csv(data_root + '/all_goodscan_list.csv')\n",
    "# df = df.loc[df['source'] != 'xnat20201031']\n",
    "# df = df.loc[df['source'] != 'xnat20201112']\n",
    "mclid_date = []\n",
    "\n",
    "for i, item in df.iterrows():\n",
    "    tmp_vec = re.split('[-_]', item['good_scan_label'])\n",
    "    if len(tmp_vec) < 2:\n",
    "        continue\n",
    "    if tmp_vec[0] == tmp_vec[1]:\n",
    "        mclid_date.append(tmp_vec[1] + '_' + tmp_vec[2])\n",
    "    else:\n",
    "        mclid_date.append(tmp_vec[0] + '_' + tmp_vec[1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/nfs/masi/MCL/QA/maintain_list/20201015/uptonow_good.csv')\n",
    "\n",
    "mclid_date_fromsess = []\n",
    "\n",
    "for i, item in df.iterrows():\n",
    "    tmp_vec = re.split('[-_]', item['sess'])\n",
    "    if len(tmp_vec) < 2:\n",
    "        continue\n",
    "    if tmp_vec[0] == tmp_vec[1]:\n",
    "        mclid_date_fromsess.append(tmp_vec[1] + '_' + tmp_vec[2])\n",
    "    else:\n",
    "        mclid_date_fromsess.append(tmp_vec[0] + '_' + tmp_vec[1])\n",
    "                \n",
    "df = pd.read_csv('/nfs/masi/MCL/QA/maintain_SCANlist/20201114/new_max_folder.csv')\n",
    "mclid_date_frommax = []\n",
    "\n",
    "for i, item in df.iterrows():\n",
    "    tmp_vec = re.split('[-_]', item['sess_label-x-SCAN_label'])\n",
    "    if len(tmp_vec) < 2:\n",
    "        continue\n",
    "    if tmp_vec[0] == tmp_vec[1]:\n",
    "        mclid_date_frommax.append(tmp_vec[1] + '_' + tmp_vec[2])\n",
    "    else:\n",
    "        mclid_date_frommax.append(tmp_vec[0] + '_' + tmp_vec[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tmp \n",
    "def norm_sessname(sess):\n",
    "    tmp_vec = re.split('[_-]', sess.strip())\n",
    "    if len(tmp_vec) < 2:\n",
    "        #print (sess)\n",
    "        return ''\n",
    "    if tmp_vec[0] != tmp_vec[1] and len(tmp_vec[1]) == 8:\n",
    "        res = tmp_vec[0] + '_' + tmp_vec[1]\n",
    "    elif tmp_vec[0] == tmp_vec[1] and len(tmp_vec[2]) == 8:\n",
    "        res = tmp_vec[1] + '_' + tmp_vec[2]\n",
    "    elif len(tmp_vec) >= 4 and len(tmp_vec[1]) == 2:\n",
    "        try:\n",
    "            assert len(tmp_vec[2]) == 2 and len(tmp_vec[3]) == 4\n",
    "            res = tmp_vec[0] + '_' + tmp_vec[3] + tmp_vec[1] + tmp_vec[2]\n",
    "        except:\n",
    "            print (tmp_vec)\n",
    "            return ''\n",
    "    else:\n",
    "        #print (sess)\n",
    "        return ''\n",
    "    return res\n",
    "mclid_date_fromsess = [norm_sessname(sess) for sess in mclid_date_fromsess]\n",
    "mclid_date_frommax = [norm_sessname(sess) for sess in mclid_date_frommax]\n",
    "mclid_date = [norm_sessname(sess) for sess in mclid_date]\n",
    "\n",
    "\n",
    "len(set(mclid_date_fromsess) - set(mclid_date_frommax) - set(mclid_date))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20817757605', '07', '16', '1']\n",
      "['20817757605', '07', '16', '2']\n",
      "['20817757605', '07', '16', '3']\n",
      "['20817757605', '07', '16', '4']\n",
      "['20817757605', '07', '16', '402']\n",
      "['20817757605', '07', '16', '401']\n",
      "['20817757605', '07', '16', '400']\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "missed_goodsess = set(mclid_date_fromsess) - set(mclid_date_frommax) - set(mclid_date)\n",
    "data_root = '/nfs/masi/MCL/xnat/MCL'\n",
    "\n",
    "df = pd.read_csv('/nfs/masi/MCL/QA/SCAN_SLICEdir/allscan_list.csv')\n",
    "allsess_list = df['scan_label'].tolist()\n",
    "# subject_list = os.listdir(data_root)\n",
    "# for subj in subject_list:\n",
    "#     allsess_list += os.listdir(data_root + '/' + subj)\n",
    "allsess_list = [norm_sessname(sess) for sess in allsess_list]\n",
    "print (len(set(missed_goodsess) - set(allsess_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "missed_good = set(missed_goodsess) - set(allsess_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1118610407_20161031',\n",
       " '11245803639_20190610',\n",
       " '12427046478_20190218',\n",
       " '14226568216_20150713',\n",
       " '16722990826_20120101',\n",
       " '17064845823_20121026',\n",
       " '17064845823_20160209',\n",
       " '17064845823_20161028',\n",
       " '17064845823_20171024',\n",
       " '17064845823_20181012',\n",
       " '17064845823_20191018',\n",
       " '17659014455_20110101',\n",
       " '19040409199_20150101',\n",
       " '21077544674_20170707',\n",
       " '22307566524_20110101',\n",
       " '2290718171_20100301',\n",
       " '23920607875_20150225',\n",
       " '24005594405_20120101',\n",
       " '29555553544_20161003',\n",
       " '29556734668_20110613',\n",
       " '31673894435_20190227',\n",
       " '32131734217_20120503',\n",
       " '33320363324_20170101',\n",
       " '35236276798_20131014',\n",
       " '35295603457_20130517',\n",
       " '41999668673_20140101',\n",
       " '4474113980_20110715',\n",
       " '5464141575_20170101',\n",
       " '7173504465_20160721',\n",
       " '8287541269_20120101',\n",
       " 'SPORE_00000087',\n",
       " 'SPORE_00000929',\n",
       " 'SPORE_00001089',\n",
       " 'SPORE_00001124'}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missed_good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/nfs/masi/MCL/xnat/MCL_all.csv')\n",
    "cnt = 0\n",
    "session_list = []\n",
    "for i, item in df.iterrows():\n",
    "    norm_sess = norm_sessname(item['session_label'])\n",
    "    if norm_sess in missed_goodsess:\n",
    "        cnt += 1\n",
    "        session_list.append(item['session_label'])\n",
    "print (cnt)\n",
    "print (len(set(session_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('/nfs/masi/MCL/file/txt/for_download/xnat20201116_scancheck_miss.txt', 'w')\n",
    "\n",
    "for sess in set(session_list):\n",
    "    f.write(sess + '\\n')\n",
    "f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python37]",
   "language": "python",
   "name": "conda-env-python37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
