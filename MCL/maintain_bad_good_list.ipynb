{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dirs \n",
    "\n",
    "xnat_root = '/nfs/masi/MCL/xnat'\n",
    "maintain_root = '/nfs/masi/MCL/QA/maintain_list'\n",
    "xnat_list = os.listdir(xnat_root)\n",
    "for xnat_name in xnat_list:\n",
    "    xname = xnat_name.split('_')[0]\n",
    "    if xname[:4] == 'xnat' and len(xname[4:]) == 8 and xname[4:] > '20200120':\n",
    "        if not os.path.exists(maintain_root + '/' + xname[4:]):\n",
    "            os.mkdir(maintain_root + '/' + xname[4:])\n",
    "        print (xname)\n",
    "    \n",
    "    #print (xname)\n",
    "print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# got the QA_bad from slicedir\n",
    "f = open('/nfs/masi/MCL/xnat/xnat20200928_makeupjustin/slicesdir.txt')\n",
    "lines = f.readlines()\n",
    "\n",
    "lines = [line.split(' ')[0] for line in lines]\n",
    "f = open('/nfs/masi/MCL/xnat/xnat20200928_makeupjustin/QA_bad.txt', 'w')\n",
    "for sess in lines:\n",
    "    f.write(sess + '\\n')\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this should be None set()\n",
      "this should be None set()\n"
     ]
    }
   ],
   "source": [
    "# generate QA_good from QA_bad\n",
    "data_root = '/nfs/masi/MCL/xnat/xnat20200928_makeupjustin'\n",
    "df = pd.read_csv(data_root + '/dicomQA_step1.csv')\n",
    "all_list = df['sess'].tolist() \n",
    "\n",
    "bad_list = open(data_root + '/QA_bad.txt').readlines()\n",
    "bad_list = [i.strip() for i in bad_list]\n",
    "print (\"this should be None\", set(bad_list) - set(all_list)) \n",
    "\n",
    "uncertain_list = open(data_root + '/lookgoodInstanceNumberbad.txt').readlines()\n",
    "uncertain_list = [i.strip() for i in uncertain_list]\n",
    "print (\"this should be None\", set(uncertain_list) - set(all_list)) \n",
    "\n",
    "good_list = set(all_list) - set(bad_list) - set(uncertain_list)\n",
    "f = open(data_root + '/QA_good.txt', 'w')\n",
    "for item in good_list:\n",
    "    f.write(item + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117 4953 113 5018\n"
     ]
    }
   ],
   "source": [
    "# the past_root and current_root should be near\n",
    "\n",
    "# NOt uncertain verison\n",
    "\n",
    "past_root = '/nfs/masi/MCL/QA/maintain_list/20200928'\n",
    "current_root = '/nfs/masi/MCL/QA/maintain_list/20201002'\n",
    "\n",
    "past_bad = pd.read_csv(past_root + '/uptonow_bad.csv')['sess'].tolist()\n",
    "\n",
    "past_good = pd.read_csv(past_root + '/uptonow_good.csv')['sess'].tolist()\n",
    "\n",
    "current_bad = open(current_root + '/QA_bad.txt').readlines()\n",
    "current_bad = [i.strip().split(' ')[0] for i in current_bad]\n",
    "\n",
    "current_good = open(current_root + '/QA_good.txt').readlines()\n",
    "current_good = [i.strip().split(' ')[0] for i in current_good]\n",
    "\n",
    "total_bad = set(current_bad) | (set(past_bad) - set(current_good))\n",
    "\n",
    "total_good = set(current_good) | (set(past_good) - set(current_bad))\n",
    "\n",
    "data = pd.DataFrame()\n",
    "\n",
    "data['sess'] = list(total_good)\n",
    "\n",
    "data.to_csv(current_root + '/uptonow_good.csv', index = False)\n",
    "\n",
    "data = pd.DataFrame()\n",
    "\n",
    "data['sess'] = list(total_bad)\n",
    "\n",
    "data.to_csv(current_root + '/uptonow_bad.csv', index = False)\n",
    "\n",
    "print (len(past_bad), len(past_good), len(total_bad), len(total_good))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the looks good, but with not good instance number\n",
    "f = open('/nfs/masi/MCL/xnat/xnat20201002_mightallbad/sldicesdirerr.txt')\n",
    "dirlines = f.readlines()\n",
    "lines = [i.strip().split(' ')[0] for i in dirlines]\n",
    "df = pd.read_csv('/nfs/masi/MCL/xnat/xnat20201002_mightallbad/dicomQA.csv')\n",
    "dfbad_list = df.loc[df['auto'] == 'bad']['sess'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('/nfs/masi/MCL/xnat/xnat20201002_mightallbad/lookbadInstanceNumbergood.txt', 'w')\n",
    "for item in set(lines) - set(dfbad_list):\n",
    "    f.write(item + '\\n')\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('/nfs/masi/MCL/xnat/xnat20201002_mightallbad/lookgoodInstanceNumberbad.txt', 'w')\n",
    "for item in set(dfbad_list) - set(lines):\n",
    "    f.write(item + '\\n')\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 4953 50 5018\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_bad = pd.read_csv(past_root + '/uptonow_bad.csv')['sess'].tolist()\n",
    "past_uncer = pd.read_csv(past_root + '/uptonow_uncertain.csv')['sess'].tolist()\n",
    "new_bad = list(set(past_bad) - set(past_uncer))\n",
    "data = pd.DataFrame()\n",
    "data['sess'] = new_bad\n",
    "data.to_csv(past_root + '/uptonow_bad.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following 4 should be all None\n",
      "set() set() set()\n",
      "set()\n",
      "66 5018 50 68 5045 50\n"
     ]
    }
   ],
   "source": [
    "# the past_root and current_root should be near\n",
    "\n",
    "# with uncertain verison\n",
    "# begin at 20200928\n",
    "\n",
    "past_root = '/nfs/masi/MCL/QA/maintain_list/20201002'\n",
    "current_root = '/nfs/masi/MCL/QA/maintain_list/20201003'\n",
    "\n",
    "past_bad = pd.read_csv(past_root + '/uptonow_bad.csv')['sess'].tolist()\n",
    "past_uncer = pd.read_csv(past_root + '/uptonow_uncertain.csv')['sess'].tolist()\n",
    "past_good = pd.read_csv(past_root + '/uptonow_good.csv')['sess'].tolist()\n",
    "\n",
    "\n",
    "current_bad = open(current_root + '/QA_bad.txt').readlines()\n",
    "current_bad = [i.strip().split(' ')[0] for i in current_bad]\n",
    "\n",
    "current_good = open(current_root + '/QA_good.txt').readlines()\n",
    "current_good = [i.strip().split(' ')[0] for i in current_good]\n",
    "\n",
    "current_uncer = open(current_root + '/lookgoodInstanceNumberbad.txt').readlines()\n",
    "current_uncer = [i.strip().split(' ')[0] for i in current_uncer]\n",
    "\n",
    "assert (len(set(past_good) & set(current_bad)) == 0) \n",
    "assert (len(set(past_good) & set(current_uncer)) == 0) \n",
    "assert (len(set(past_uncer) & set(current_bad)) == 0)\n",
    "\n",
    "total_bad = set(current_bad) | (set(past_bad) - set(current_good) - set(current_uncer))\n",
    "\n",
    "total_uncer = set(current_uncer) | (set(past_uncer) - set(current_good))\n",
    "\n",
    "total_good = set(current_good) | (set(past_good) - set(current_bad) - set(current_good))\n",
    "\n",
    "print ('The following 4 should be all None')\n",
    "print (total_bad & total_uncer, total_good & total_uncer, total_good & total_bad)\n",
    "print (set(past_bad) & set(past_uncer))\n",
    "\n",
    "data = pd.DataFrame()\n",
    "\n",
    "data['sess'] = list(total_good)\n",
    "\n",
    "data.to_csv(current_root + '/uptonow_good.csv', index = False)\n",
    "\n",
    "data = pd.DataFrame()\n",
    "\n",
    "data['sess'] = list(total_bad)\n",
    "\n",
    "data.to_csv(current_root + '/uptonow_bad.csv', index = False)\n",
    "\n",
    "data = pd.DataFrame()\n",
    "\n",
    "data['sess'] = list(total_uncer)\n",
    "\n",
    "data.to_csv(current_root + '/uptonow_uncertain.csv', index = False)\n",
    "\n",
    "print (len(past_bad), len(past_good), len(past_uncer), len(total_bad), len(total_good), len(total_uncer))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "{'41292354607-20150123', '26685639639-20150527'}\n",
      "set()\n",
      "217 10 21\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "data_root = '/nfs/masi/MCL/QA/maintain_list/20200928'\n",
    "good_list = open(data_root + '/QA_good.txt').readlines()\n",
    "good_list = [i.strip() for i in good_list]\n",
    "bad_list = open(data_root + '/QA_bad.txt').readlines()\n",
    "bad_list = [i.strip() for i in bad_list]\n",
    "uncer_list = open(data_root + '/lookgoodInstanceNumberbad.txt').readlines()\n",
    "uncer_list = [i.strip() for i in uncer_list]\n",
    "print (set(good_list) & set(bad_list))\n",
    "print (set(uncer_list) & set(bad_list))\n",
    "print (set(good_list) & set(uncer_list))\n",
    "print (len(set(good_list)), len(set(bad_list)), len(set(uncer_list)))\n",
    "good_list2 = pd.read_csv(data_root + '/uptonow_good.csv')['sess'].tolist()\n",
    "print (set(good_list2) & set(bad_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'9937003500-20140327', '10817759785_20140905_155950_512', '20981799122_20130409_090122', '18123771639-20160613', '2928454691_20180530_100910', '21874019371_20120330_082618_162', '5046728432_20190912_165528_888000', '21874019371_20120202_152524_800', '31008457529-20150422', '18953108760-20170509'}\n",
      "{'26100447864-20151120', '3958863861-20140220', '26441976903-20180125', '13790385981-20170919', '37847697330-20160812', '7295991603-20161128', '8573381504-20170609', '41292354607-20150123', '12697747980-20160425', '8974639241-20150821', '12697747980-20150914', '3958863861-20160425', '26685639639-20150527', '1873918011-20170526', '12697747980-20140905', '26441976903-20180122', '29569544379-20140710', '29550499216-20151229', '12697747980-20161010', '24251918406-20041116', '37861465545-20161212'}\n",
      "set()\n",
      "5018 97 50\n"
     ]
    }
   ],
   "source": [
    "# ensure not overlapp\n",
    "data_root = '/nfs/masi/MCL/QA/maintain_list/20201002'\n",
    "good_list = pd.read_csv(data_root + '/uptonow_good.csv')['sess'].tolist()\n",
    "bad_list = pd.read_csv(data_root + '/uptonow_bad.csv')['sess'].tolist()\n",
    "uncer_list = pd.read_csv(data_root + '/uptonow_uncertain.csv')['sess'].tolist()\n",
    "print (set(good_list) & set(bad_list))\n",
    "print (set(uncer_list) & set(bad_list))\n",
    "print (set(good_list) & set(uncer_list))\n",
    "print (len(set(good_list)), len(set(bad_list)), len(set(uncer_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20200815', 'before20191218', '20200901', 'code', '20200206_xinmeng', '20200130', 'before201906', '20200201', '20200306', '20200106', '20200816', '20200504', '20200902', '20200115', '20200311', '20200127', '20200120', '20200522', '20200131', '20200128', '20200512', 'readme.txt', '20200326', '20200110', '20200117', '20200207', '20200222', '20200121', '20200424', '20200909', '20200505']\n",
      "['20200106', '20200110', '20200115', '20200117', '20200120', '20200121', '20200127', '20200128', '20200130', '20200131', '20200201', '20200206_xinmeng', '20200207', '20200222', '20200306', '20200311', '20200326', '20200424', '20200504', '20200505', '20200512', '20200522', '20200815', '20200816', '20200901', '20200902', '20200909', 'before201906', 'before20191218', 'code', 'readme.txt']\n"
     ]
    }
   ],
   "source": [
    "data_list = os.listdir('/nfs/masi/MCL/QA/maintain_list')\n",
    "print (data_list)\n",
    "print (sorted(data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp \n",
    "\n",
    "f = open('/nfs/masi/MCL/QA/maintain_list/20200928/uptonow_uncertain.txt')\n",
    "lines = f.readlines()\n",
    "lines = [line.strip() for line in lines]\n",
    "data = pd.DataFrame()\n",
    "\n",
    "data['sess'] = lines\n",
    "data.to_csv('/nfs/masi/MCL/QA/maintain_list/20200928/uptonow_uncertain.csv', index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_root = '/nfs/masi/MCL/xnat/MCL'\n",
    "subj_list = os.listdir(data_root)\n",
    "total_sess = []\n",
    "f = open('/nfs/masi/MCL/xnat/xnat20200928_makeupjustin/need_sess_path.txt', 'w')\n",
    "for subj in subj_list:\n",
    "    sess_list = os.listdir(data_root + '/' + subj)\n",
    "    for sess in sess_list:\n",
    "        if sess in need_sess:\n",
    "            f.write(data_root + '/' + subj + '/' + sess + '\\n')\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241\n"
     ]
    }
   ],
   "source": [
    "print (len((set(total_sess)) & set(past_bad)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "need_sess = (set(total_sess)) & set(past_bad)\n",
    "f = open('/nfs/masi/MCL/xnat/xnat20200928_makeupjustin/need_sess.csv', 'w')\n",
    "for sess in need_sess:\n",
    "    f.write(sess + '\\n')\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/nfs/masi/MCL/xnat/xnat20201002_mightallbad/Riqiang_10_2_2020_16_37_59.csv')\n",
    "\n",
    "all_sess = df['XNAT_CTSESSIONDATA ID'].tolist()\n",
    "\n",
    "df1 = pd.read_csv('/nfs/masi/MCL/xnat/xnat20200928_makeupjustin/dicomQA_step1.csv')\n",
    "df2 = pd.read_csv('/nfs/masi/MCL/xnat/xnat20200928_makeupjustin/dicomQA_step2.csv')\n",
    "\n",
    "sess0928 = df1['sess'].tolist() + df2['sess'].tolist()\n",
    "\n",
    "df_pre = pd.read_csv('/nfs/masi/MCL/QA/maintain_list/20200909/uptonow_good.csv')\n",
    "sess_pre = df_pre['sess'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "need = set(all_sess) - set(sess0928) - set(sess_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('/nfs/masi/MCL/file/txt/for_download/xnat20201002_mightallbad.txt', 'w')\n",
    "for sess in need:\n",
    "    f.write(sess + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/nfs/masi/MCL/QA/maintain_list/20200909/uptonow_bad.csv')\n",
    "bad_list = df['sess'].tolist()\n",
    "df = pd.read_csv('/nfs/masi/MCL/QA/maintain_list/20200909/uptonow_good.csv')\n",
    "good_list = df['sess'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329 4741\n"
     ]
    }
   ],
   "source": [
    "print (len(bad_list), len(good_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(bad_list) & set(good_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python37]",
   "language": "python",
   "name": "conda-env-python37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
